---
title: "Weighted Least Squares"
author: "Minah Ramandrosoa"
date: "2024-06"
output: github_document
---

```{r setup, include=FALSE}
# This chunk is usually used to set global options and load libraries
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


In linear regression, having a constant variance of the error terms $E_i$  (homoscedasticity) is essential to ensure the validity of statistical inference, maintain the accuracy of predictions and correctly interpret the results of the model 

The Weighted Least Squares is an alternative of the Ordinary Least Squares in order to address the non-constant variance of the error terms(heteroscedasticity).

Consider the following simple linear regression model taking a sample of n data points $(x_i,y_i)$  : 

  $y_i = B_0 + B_1x_i + E_i$ , $E_i \sim N(0,xi\sigma^{2})$

A priori, the variance of the residuals increased with the regressors. 
  
Then, $Var(y_i) = Var(E_i) = x_i\sigma^{2}$

However, the relationship between the independent variable and the variance of the residuals is not always as straightforward.  

Consider $X$ as the transformation applied on the residuals, then we have :

  $Var(E_i') = Var(XE_i)$

Applying the scaling of the variance upon multiplication with a constant, where $X$ is the constant : 
  
  $Var(XE_i) = X^{2}Var(E_i)$
  
  $Var(XE_i) = X^{2}x_i\sigma^{2}$
  
As we want to get a constant variance, we will be looking for a transformation that will delete $x_i$, 

then, 

$$
X^{2} = \frac{1}{x_i} 
$$

and

$$
X = \frac{1}{\sqrt{x_i}}
$$

  $Var(XE_i) = (\frac{1}{x_i})x_i\sigma^{2}$
  
  $Var(E_i') = Var(XE_i) = \sigma^{2}$
  
To stabilize the variance, we let : 

$$
E_i' = XE_i = \frac{E_i}{{\sqrt{{x_i}}}} ~ N(0,\sigma^{2}), i = 1,...,n
$$
  
Recall the original model :

  $y_i = B_0 + B_1x_i + E_i$
  
We rewrite it as follow :

  $\frac{y_i}{\sqrt{{x_i}}}$ = $B_0(\frac{1}{{\sqrt{x_i}}} )$ + $B_1x_i(\frac{1}{{\sqrt{x_i}}}  )$+ $E_i'$
  
  $\frac{y_i}{\sqrt{{x_i}}}$ = $B_0(\frac{1}{{\sqrt{x_i}}} )$ + $B_1{\sqrt{x_i}}$+ $E_i'$
  
The sum of the weighted errors are given by :

$$
\Sigma_{i=1}^{n} (E_i')^{2} =  \Sigma_{i=1}^{n}(\frac{y_i}{\sqrt{{x_i}}}-B_0(\frac{1}{{\sqrt{x_i}}} )-B_1{\sqrt{x_i}} )^{2}
$$

  
$$
\Sigma_{i=1}^{n} (E_i')^{2} = \Sigma_{i=1}^{n} (\frac{1}{x_i}) (y_i-B_o -B_1x_i)^2
$$
  
We get the following weighted least squares function which we will minimize :


$$
S(B_0, B_1) =\Sigma_{i=1}^{n} (\frac{1}{x_i})(y_i-B_o -B_1x_i)^2
$$
  
In this simple linear regression, the weight that stabilizes the variance of the residuals is denoted as $wi = \frac{1}{x_i}$. 

Notice that a high value of $x_i$ implies a low weight, while the spread of the residuals increases with the regressor $x_i$. This means that :

  - observations with higher variance result in lower weight
  - observations with lower variance result in higher weight
  
In this context, we can conclude that the weights are inversely related to the variance. Then we get $w_i = \frac{1}{\sigma^2}$.  

```{r}
data_WLS <- read.csv("C:/Users/USER/Desktop/IIT/data_WLS.csv")
x<-data_WLS$x
y<-data_WLS$y

model_OLS <- lm(y~x)
plot(x,y)
```

This plot clearly indicates that the higher the value of x, the wider the spread of y. 

Let us perform a Breusch-Pagan test to check the heteroscedasticity.
The null hypothesis states that the variance of errors is constant, indicating homoscedasticity.

```{r}
library(lmtest)
bptest(model_OLS)
```

Since the p-value is lower than the significance level of 0.05, we reject the null hypothesis of homoscedasticity. This indicates that the variance of the residuals is not constant. 

To address heteroscedasticity, we will implement a new model using weights to correct for the non-constant variance.

For instance,  $w_i = \frac{1}{x_i}$

```{r}
w<- 1/(x)
  #implement a new model
model_WLS<- lm(y~x, weights = w ) 
  #perform Breusch-Pagan test
bptest(model_WLS)
```

Since the p-value is now greater than the significance level of 0.05, we fail to reject the null hypothesis of homoscedasticity. This suggests that there is no strong evidence to conclude that the variance of the residuals is non-constant. 

This result indicates that the weighting we have implemented effectively addresses any initial heteroscedasticity observed in the model, supporting the assumption of constant variance in the residuals. 
